{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_neox.embed_in.weight: torch.Size([50304, 1024])\n",
      "gpt_neox.layers.0.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.0.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.0.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.0.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.0.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.0.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.0.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.0.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.0.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.0.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.0.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.1.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.1.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.1.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.1.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.1.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.1.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.1.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.1.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.1.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.1.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.1.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.2.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.2.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.2.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.2.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.2.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.2.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.2.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.2.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.2.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.2.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.2.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.3.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.3.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.3.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.3.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.3.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.3.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.3.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.3.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.3.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.3.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.3.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.4.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.4.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.4.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.4.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.4.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.4.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.4.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.4.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.4.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.4.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.4.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.5.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.5.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.5.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.5.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.5.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.5.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.5.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.5.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.5.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.5.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.5.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.6.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.6.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.6.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.6.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.6.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.6.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.6.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.6.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.6.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.6.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.6.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.6.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.6.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.7.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.7.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.7.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.7.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.7.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.7.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.7.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.7.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.7.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.7.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.7.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.7.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.7.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.8.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.8.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.8.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.8.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.8.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.8.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.8.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.8.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.8.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.8.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.8.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.8.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.8.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.9.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.9.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.9.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.9.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.9.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.9.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.9.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.9.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.9.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.9.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.9.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.9.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.9.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.10.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.10.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.10.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.10.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.10.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.10.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.10.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.10.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.10.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.10.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.10.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.10.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.10.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.11.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.11.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.11.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.11.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.11.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.11.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.11.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.11.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.11.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.11.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.11.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.11.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.11.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.12.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.12.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.12.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.12.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.12.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.12.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.12.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.12.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.12.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.12.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.12.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.12.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.12.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.13.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.13.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.13.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.13.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.13.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.13.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.13.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.13.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.13.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.13.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.13.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.13.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.13.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.14.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.14.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.14.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.14.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.14.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.14.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.14.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.14.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.14.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.14.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.14.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.14.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.14.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.15.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.15.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.15.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.15.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.15.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.15.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.15.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.15.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.15.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.15.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.15.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.15.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.15.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.16.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.16.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.16.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.16.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.16.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.16.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.16.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.16.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.16.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.16.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.16.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.16.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.16.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.17.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.17.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.17.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.17.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.17.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.17.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.17.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.17.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.17.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.17.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.17.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.17.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.17.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.18.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.18.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.18.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.18.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.18.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.18.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.18.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.18.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.18.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.18.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.18.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.18.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.18.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.19.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.19.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.19.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.19.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.19.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.19.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.19.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.19.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.19.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.19.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.19.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.19.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.19.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.20.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.20.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.20.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.20.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.20.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.20.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.20.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.20.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.20.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.20.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.20.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.20.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.20.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.21.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.21.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.21.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.21.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.21.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.21.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.21.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.21.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.21.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.21.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.21.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.21.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.21.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.22.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.22.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.22.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.22.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.22.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.22.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.22.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.22.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.22.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.22.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.22.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.22.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.22.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.layers.23.input_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.23.input_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.23.post_attention_layernorm.weight: torch.Size([1024])\n",
      "gpt_neox.layers.23.post_attention_layernorm.bias: torch.Size([1024])\n",
      "gpt_neox.layers.23.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "gpt_neox.layers.23.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "gpt_neox.layers.23.attention.query_key_value.bias: torch.Size([3072])\n",
      "gpt_neox.layers.23.attention.dense.weight: torch.Size([1024, 1024])\n",
      "gpt_neox.layers.23.attention.dense.bias: torch.Size([1024])\n",
      "gpt_neox.layers.23.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "gpt_neox.layers.23.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "gpt_neox.layers.23.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "gpt_neox.layers.23.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "gpt_neox.final_layer_norm.weight: torch.Size([1024])\n",
      "gpt_neox.final_layer_norm.bias: torch.Size([1024])\n",
      "embed_out.weight: torch.Size([50304, 1024])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Load the model with remote code for causal language modeling\n",
    "model_name = \"EleutherAI/pythia-410m\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# Print the state dictionary keys to understand the structure\n",
    "state_dict = model.state_dict()\n",
    "for key, value in state_dict.items():\n",
    "    print(f\"{key}: {value.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTNeoXForCausalLM(\n",
      "  (gpt_neox): GPTNeoXModel(\n",
      "    (embed_in): Embedding(50304, 1024)\n",
      "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x GPTNeoXLayer(\n",
      "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (attention): GPTNeoXAttention(\n",
      "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): GPTNeoXMLP(\n",
      "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (act): GELUActivation()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (embed_out): Linear(in_features=1024, out_features=50304, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 396/396 [00:00<00:00, 58.3kB/s]\n",
      "tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 6.29MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 99.0/99.0 [00:00<00:00, 202kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/ubuntu/LLM-Shearing/models/pythia-410m/tokenizer_config.json',\n",
       " '/home/ubuntu/LLM-Shearing/models/pythia-410m/special_tokens_map.json',\n",
       " '/home/ubuntu/LLM-Shearing/models/pythia-410m/tokenizer.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Download and save the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"EleutherAI/pythia-410m\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Save it to your desired path\n",
    "save_path = \"/home/ubuntu/LLM-Shearing/models/pythia-410m\"\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer was not provided. This means the tokenizer config will not be saved in the checkpoint.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.gpt_neox.embed_in.weight: torch.Size([50304, 1024])\n",
      "model.gpt_neox.layers.0.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.0.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.0.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.0.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.0.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.0.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.0.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.0.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.0.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.0.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.0.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.0.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.0.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.1.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.1.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.1.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.1.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.1.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.1.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.1.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.1.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.1.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.1.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.1.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.1.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.1.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.2.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.2.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.2.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.2.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.2.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.2.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.2.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.2.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.2.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.2.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.2.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.2.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.2.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.3.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.3.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.3.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.3.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.3.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.3.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.3.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.3.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.3.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.3.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.3.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.3.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.3.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.4.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.4.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.4.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.4.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.4.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.4.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.4.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.4.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.4.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.4.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.4.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.4.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.4.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.5.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.5.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.5.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.5.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.5.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.5.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.5.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.5.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.5.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.5.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.5.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.5.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.5.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.6.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.6.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.6.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.6.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.6.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.6.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.6.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.6.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.6.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.6.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.6.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.6.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.6.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.7.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.7.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.7.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.7.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.7.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.7.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.7.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.7.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.7.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.7.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.7.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.7.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.7.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.8.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.8.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.8.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.8.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.8.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.8.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.8.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.8.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.8.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.8.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.8.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.8.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.8.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.9.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.9.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.9.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.9.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.9.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.9.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.9.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.9.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.9.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.9.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.9.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.9.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.9.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.10.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.10.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.10.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.10.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.10.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.10.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.10.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.10.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.10.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.10.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.10.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.10.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.10.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.11.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.11.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.11.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.11.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.11.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.11.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.11.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.11.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.11.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.11.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.11.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.11.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.11.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.12.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.12.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.12.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.12.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.12.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.12.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.12.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.12.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.12.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.12.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.12.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.12.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.12.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.13.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.13.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.13.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.13.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.13.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.13.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.13.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.13.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.13.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.13.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.13.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.13.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.13.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.14.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.14.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.14.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.14.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.14.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.14.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.14.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.14.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.14.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.14.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.14.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.14.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.14.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.15.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.15.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.15.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.15.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.15.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.15.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.15.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.15.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.15.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.15.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.15.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.15.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.15.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.16.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.16.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.16.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.16.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.16.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.16.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.16.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.16.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.16.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.16.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.16.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.16.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.16.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.17.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.17.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.17.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.17.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.17.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.17.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.17.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.17.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.17.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.17.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.17.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.17.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.17.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.18.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.18.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.18.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.18.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.18.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.18.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.18.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.18.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.18.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.18.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.18.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.18.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.18.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.19.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.19.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.19.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.19.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.19.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.19.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.19.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.19.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.19.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.19.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.19.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.19.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.19.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.20.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.20.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.20.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.20.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.20.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.20.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.20.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.20.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.20.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.20.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.20.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.20.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.20.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.21.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.21.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.21.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.21.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.21.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.21.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.21.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.21.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.21.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.21.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.21.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.21.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.21.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.22.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.22.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.22.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.22.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.22.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.22.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.22.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.22.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.22.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.22.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.22.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.22.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.22.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.23.input_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.23.input_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.23.post_attention_layernorm.weight: torch.Size([1024])\n",
      "model.gpt_neox.layers.23.post_attention_layernorm.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.23.attention.rotary_emb.inv_freq: torch.Size([8])\n",
      "model.gpt_neox.layers.23.attention.query_key_value.weight: torch.Size([3072, 1024])\n",
      "model.gpt_neox.layers.23.attention.query_key_value.bias: torch.Size([3072])\n",
      "model.gpt_neox.layers.23.attention.dense.weight: torch.Size([1024, 1024])\n",
      "model.gpt_neox.layers.23.attention.dense.bias: torch.Size([1024])\n",
      "model.gpt_neox.layers.23.mlp.dense_h_to_4h.weight: torch.Size([4096, 1024])\n",
      "model.gpt_neox.layers.23.mlp.dense_h_to_4h.bias: torch.Size([4096])\n",
      "model.gpt_neox.layers.23.mlp.dense_4h_to_h.weight: torch.Size([1024, 4096])\n",
      "model.gpt_neox.layers.23.mlp.dense_4h_to_h.bias: torch.Size([1024])\n",
      "model.gpt_neox.final_layer_norm.weight: torch.Size([1024])\n",
      "model.gpt_neox.final_layer_norm.bias: torch.Size([1024])\n",
      "model.embed_out.weight: torch.Size([50304, 1024])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from composer.models.huggingface import HuggingFaceModel\n",
    "\n",
    "# Load the model with remote code for causal language modeling\n",
    "model_name = \"EleutherAI/pythia-410m\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "composer_model = HuggingFaceModel(model)\n",
    "\n",
    "print(composer_model)\n",
    "\n",
    "# Print the state dictionary keys and shapes\n",
    "state_dict = composer_model.state_dict()\n",
    "for key, value in state_dict.items():\n",
    "    print(f\"{key}: {value.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFaceModel(\n",
      "  (model): GPTNeoXForCausalLM(\n",
      "    (gpt_neox): GPTNeoXModel(\n",
      "      (embed_in): Embedding(50304, 1024)\n",
      "      (emb_dropout): Dropout(p=0.0, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0-23): 24 x GPTNeoXLayer(\n",
      "          (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (attention): GPTNeoXAttention(\n",
      "            (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "            (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (mlp): GPTNeoXMLP(\n",
      "            (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (act): GELUActivation()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (embed_out): Linear(in_features=1024, out_features=50304, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(composer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the state dictionary keys and shapes\n",
    "state_dict = composer_model.state_dict()\n",
    "for key, value in state_dict.items():\n",
    "    print(f\"{key}: {value.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from omegaconf import OmegaConf\n",
    "from llmshearing.models.composer_pythia import ComposerMosaicPythia\n",
    "\n",
    "def load_pretrained_weights(model, pretrained_path):\n",
    "    \"\"\"Load pretrained weights into the Pythia model.\"\"\"\n",
    "    pretrained = AutoModelForCausalLM.from_pretrained(pretrained_path)\n",
    "    \n",
    "    # Map and load weights\n",
    "    state_dict = pretrained.state_dict()\n",
    "    model_dict = model.state_dict()\n",
    "    \n",
    "    # You might need to adjust the key mapping based on your implementation\n",
    "    for k, v in state_dict.items():\n",
    "        if k in model_dict:\n",
    "            model_dict[k].copy_(v)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generate_with_pythia(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt,\n",
    "    max_length=100,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    num_return_sequences=1\n",
    "):\n",
    "    \"\"\"Generate text using the Pythia model with better decoding.\"\"\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        input_ids = input_ids.cuda()\n",
    "        model = model.cuda()\n",
    "    \n",
    "    # Set up generation\n",
    "    generated = input_ids\n",
    "    past_key_values = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            outputs = model(\n",
    "                generated[:, -1:] if past_key_values is not None else generated,\n",
    "                past_key_values=past_key_values\n",
    "            )\n",
    "            \n",
    "            logits = outputs['logits'][:, -1, :]\n",
    "            \n",
    "            # Apply temperature\n",
    "            logits = logits / temperature\n",
    "            \n",
    "            # Apply top-p (nucleus) sampling\n",
    "            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "            cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "            sorted_indices_to_remove = cumulative_probs > top_p\n",
    "            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "            sorted_indices_to_remove[..., 0] = 0\n",
    "            indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
    "            logits[indices_to_remove] = float('-inf')\n",
    "            \n",
    "            # Sample next token\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            generated = torch.cat([generated, next_token], dim=1)\n",
    "            \n",
    "            if next_token.item() == tokenizer.eos_token_id:\n",
    "                break\n",
    "    \n",
    "    return tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "\n",
    "def test_pythia():\n",
    "    # 1. Load config (adjust paths/values as needed)\n",
    "    cfg = {\n",
    "        'name': 'pythia-410',\n",
    "        'vocab_size': 50304,\n",
    "        'd_model': 1024,\n",
    "        'n_heads': 16,\n",
    "        'n_layers': 12,\n",
    "        'max_seq_len': 2048,\n",
    "        'attn_impl': 'flash',\n",
    "        'rotary_pct': 0.25,\n",
    "        'layer_norm_eps': 1e-5,\n",
    "        'intermediate_size': 4096,\n",
    "        'init_device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    }\n",
    "    cfg = OmegaConf.create(cfg)\n",
    "\n",
    "    # 2. Initialize model and tokenizer\n",
    "    model = ComposerMosaicPythia(cfg)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-410m\")\n",
    "    \n",
    "    # 3. Load pretrained weights (optional)\n",
    "    model = load_pretrained_weights(model, \"EleutherAI/pythia-410m\")\n",
    "    \n",
    "    # 4. Test generation\n",
    "    prompts = [\n",
    "        \"Once upon a time\",\n",
    "        \"The meaning of life is\",\n",
    "        \"In the year 2050,\"\n",
    "    ]\n",
    "    \n",
    "    for prompt in prompts:\n",
    "        generated_text = generate_with_pythia(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            prompt,\n",
    "            max_length=100,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9\n",
    "        )\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        print(f\"Generated: {generated_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "test_pythia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... existing code where model is loaded ...\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# Add this code to get parameter count\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
